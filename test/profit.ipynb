{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from time import sleep\n",
    "from tqdm import tqdm, trange\n",
    "from pymongo import MongoClient, errors\n",
    "from lightweight_charts import JupyterChart\n",
    "from collections import deque\n",
    "from icecream import ic\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = 'localhost'\n",
    "port = 27017\n",
    "db_name = 'oquant_runtime'\n",
    "coll_name = '1234:group_prices'\n",
    "strategy_id = '3'\n",
    "\n",
    "client = MongoClient(host, port, serverSelectionTimeoutMS=5000)\n",
    "db = client[db_name]\n",
    "coll = db[coll_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过交易信息计算收益\n",
    "simple_desc =  {}\n",
    "for record in db['1234:trades'].find({'strategy_id': strategy_id}):\n",
    "    dt = f'{record[\"date\"]} {record[\"time\"]}'\n",
    "    price = record['price'] if record['direction'] == '卖' else -record['price']\n",
    "    if price == 0:\n",
    "        continue\n",
    "    if record['code'] not in simple_desc:\n",
    "        simple_desc[record['code']] = [price]\n",
    "    else:\n",
    "        simple_desc[record['code']].append(price)\n",
    "sum([sum(v) for v in list(simple_desc.values())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.6738"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def to_straddle_group(df):    \n",
    "#     def split_series(s, n):\n",
    "#         # 将Series转换为numpy数组\n",
    "#         arr = s.to_numpy()\n",
    "        \n",
    "#         # 计算连续NaN的个数\n",
    "#         mask = np.concatenate(([False], np.isnan(arr), [False]))\n",
    "#         idx = np.flatnonzero(mask[1:] != mask[:-1])\n",
    "#         counts = idx[1::2] - idx[::2]\n",
    "        \n",
    "#         # 找到连续NaN个数超过n的位置\n",
    "#         split_points = idx[1::2][counts >= n]\n",
    "        \n",
    "#         # 分段并删除NaN\n",
    "#         segments = np.split(s, split_points)\n",
    "#         segments = [segment.dropna() for segment in segments]\n",
    "        \n",
    "#         # 获取每个分段的起始和结束位置\n",
    "#         positions = [(segment.index[0], segment.index[-1]) for segment in segments if len(segment) > 0]\n",
    "        \n",
    "#         return positions\n",
    "\n",
    "#     def get_origin_seqments(df):\n",
    "#         # 分段并删除连续NaN个数超过2的部分\n",
    "#         undl_symbol = None\n",
    "#         positions = []\n",
    "#         symbols = []\n",
    "#         for i in range(1, len(df.columns)):\n",
    "#             symbol = df.columns[i]\n",
    "#             pos = split_series(df.iloc[:, i], 50)\n",
    "#             if len(pos) == 1 and pos[0][1] - pos[0][0] + 5 >= len(df) and undl_symbol is None:\n",
    "#                 undl_symbol = symbol\n",
    "#             else:\n",
    "#                 [positions.append(p) for p in pos]\n",
    "#                 for i in range(len(pos)):\n",
    "#                     symbols.append(symbol)\n",
    "        \n",
    "#         return {\n",
    "#             'underlying_symbol': undl_symbol,\n",
    "#             'positions': positions,\n",
    "#             'symbols': symbols\n",
    "#         }\n",
    "        \n",
    "#     def decompose_tuples(lst):\n",
    "#         result = {\"old\": [], \"new\": []}\n",
    "#         for i in range(len(lst)):\n",
    "#             overlaps = [j for j in range(len(lst)) if lst[j][0] >= lst[i][0] and lst[j][1] <= lst[i][1] and j != i]\n",
    "#             if len(overlaps) >= 2:\n",
    "#                 result[\"old\"].append(lst[i])\n",
    "#                 result[\"new\"].extend([lst[j] for j in overlaps])\n",
    "#         return result\n",
    "        \n",
    "#     def get_new_seqments_info(df):\n",
    "#         info = get_origin_seqments(df)\n",
    "#         undl_symbol = info['underlying_symbol']\n",
    "#         positions = info['positions']\n",
    "#         symbols = info['symbols']\n",
    "\n",
    "#         changed_positions = decompose_tuples(positions)\n",
    "#         indexes = []\n",
    "#         for i in range(len(changed_positions['old'])):\n",
    "#             idx = positions.index(changed_positions['old'][i])\n",
    "#             indexes.append(idx)\n",
    "#             positions.extend(changed_positions['new'])\n",
    "#             symbols.extend([symbols[idx]] * len(changed_positions['new'][i]))\n",
    "#         positions = [pos for idx, pos in enumerate(positions) if idx not in indexes]\n",
    "#         symbols = [sym for idx, sym in enumerate(symbols) if idx not in indexes]\n",
    "        \n",
    "#         return {\n",
    "#             'underlying_symbol': undl_symbol,\n",
    "#             'positions': positions,\n",
    "#             'symbols': symbols\n",
    "#         }\n",
    "        \n",
    "#     def pair_tuples(tuples):\n",
    "#         # 按照范围的开始进行排序\n",
    "#         tuples = tuples.copy()\n",
    "#         tuples.sort(key=lambda x: x[0])\n",
    "        \n",
    "#         pairs = []\n",
    "#         while tuples:\n",
    "#             # 选择范围最大的元组\n",
    "#             max_range_tuple = max(tuples, key=lambda x: x[1])\n",
    "#             tuples.remove(max_range_tuple)\n",
    "            \n",
    "#             # 寻找可以被当前元组包含的元组\n",
    "#             for i in range(len(tuples)):\n",
    "#                 if tuples[i][0] >= max_range_tuple[0] and tuples[i][1] <= max_range_tuple[1]:\n",
    "#                     pairs.append((max_range_tuple, tuples[i]))\n",
    "#                     tuples.pop(i)\n",
    "#                     break\n",
    "        \n",
    "#         return pairs\n",
    "\n",
    "#     def create_group(df):\n",
    "#         info = get_new_seqments_info(df)\n",
    "#         undl_symbol = info['underlying_symbol']\n",
    "#         positions = info['positions']\n",
    "#         symbols = info['symbols']\n",
    "#         positions = [(b[0], b[1], a) for a, b in zip(symbols, positions)]\n",
    "#         pairs = pair_tuples(positions)\n",
    "        \n",
    "#         df[undl_symbol].ffill(inplace=True)\n",
    "#         work_dfs = []\n",
    "#         pairs.sort(key=lambda x: x[0][0])\n",
    "#         for pair in pairs:\n",
    "#             start_pos = min(pair[0][0], pair[1][0])\n",
    "#             end_pos = max(pair[0][1], pair[1][1])\n",
    "#             data = df.loc[start_pos:end_pos, ['datetime', undl_symbol, pair[0][2], pair[1][2]]]\n",
    "#             # ic(pair)\n",
    "#             data['TotalPrice'] = data[pair[0][2]] + data[pair[1][2]]\n",
    "#             data.bfill(inplace=True)\n",
    "#             data.set_index('datetime', drop=True, inplace=True)\n",
    "            \n",
    "#             data['Rise'] = data['TotalPrice'].shift(1) - data['TotalPrice']\n",
    "            \n",
    "#             work_dfs.append(data)\n",
    "        \n",
    "#         return work_dfs\n",
    "    \n",
    "#     return create_group(df)\n",
    "\n",
    "class Axis:\n",
    "    \n",
    "    def __init__(self, name, start, end):\n",
    "        self.name = name\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Axis(name='{self.name}', start={self.start}, end={self.end})\"\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        \"\"\"根据开始位置进行比较，以实现排序。\"\"\"\n",
    "        if self.end < other.end:\n",
    "            return True\n",
    "        elif self.end == other.end:\n",
    "            return self.start > other.start\n",
    "        return False\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        if self.start <= other.start and self.end >= other.end:\n",
    "            return Axis(self.name, self.start, other.start) if other.start > self.start else None\n",
    "        \n",
    "        raise ValueError('不能消除数轴，请检查价格分组数据')\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    def merge(axes, gap=10):\n",
    "        if len(axes) < 2:\n",
    "            return axes\n",
    "        _axes = deque(sorted(axes).copy())\n",
    "        base = _axes.popleft()\n",
    "        new_axes = []\n",
    "        while len(_axes) > 0:\n",
    "            other = _axes.popleft()\n",
    "            if other.start - base.end <= gap:\n",
    "                base = Axis(base.name, base.start, other.end)\n",
    "            else:\n",
    "                new_axes.append(base)\n",
    "                base = other\n",
    "        new_axes.append(base)\n",
    "        \n",
    "        return new_axes\n",
    " \n",
    "def to_straddle_group(df):    \n",
    "    def split_series(s, n):\n",
    "        # 将Series转换为numpy数组\n",
    "        arr = s.to_numpy()\n",
    "        \n",
    "        # 计算连续NaN的个数\n",
    "        mask = np.concatenate(([False], np.isnan(arr), [False]))\n",
    "        idx = np.flatnonzero(mask[1:] != mask[:-1])\n",
    "        counts = idx[1::2] - idx[::2]\n",
    "        \n",
    "        # 找到连续NaN个数超过n的位置\n",
    "        split_points = idx[1::2][counts >= n]\n",
    "        \n",
    "        # 分段并删除NaN\n",
    "        segments = np.split(s, split_points)\n",
    "        segments = [segment.dropna() for segment in segments]\n",
    "        \n",
    "        # 获取每个分段的起始和结束位置\n",
    "        positions = [(segment.index[0], segment.index[-1]) for segment in segments if len(segment) > 0]\n",
    "        \n",
    "        return positions\n",
    "\n",
    "    def get_origin_seqments(df):\n",
    "        # 分段并删除连续NaN个数超过2的部分\n",
    "        undl_symbol = None\n",
    "        positions = []\n",
    "        symbols = []\n",
    "        for i in range(1, len(df.columns)):\n",
    "            symbol = df.columns[i]\n",
    "            pos = split_series(df.iloc[:, i], 50)\n",
    "            if len(pos) == 1 and pos[0][1] - pos[0][0] + 5 >= len(df) and undl_symbol is None:\n",
    "                undl_symbol = symbol\n",
    "            else:\n",
    "                [positions.append(p) for p in pos]\n",
    "                for i in range(len(pos)):\n",
    "                    symbols.append(symbol)\n",
    "        \n",
    "        return {\n",
    "            'underlying_symbol': undl_symbol,\n",
    "            'positions': positions,\n",
    "            'symbols': symbols\n",
    "        }\n",
    "        \n",
    "    def decompose_tuples(lst):\n",
    "        result = {\"old\": [], \"new\": []}\n",
    "        for i in range(len(lst)):\n",
    "            overlaps = [j for j in range(len(lst)) if lst[j][0] >= lst[i][0] and lst[j][1] <= lst[i][1] and j != i]\n",
    "            if len(overlaps) >= 2:\n",
    "                result[\"old\"].append(lst[i])\n",
    "                result[\"new\"].extend([lst[j] for j in overlaps])\n",
    "        return result\n",
    "        \n",
    "    def get_new_seqments_info(df):\n",
    "        info = get_origin_seqments(df)\n",
    "        undl_symbol = info['underlying_symbol']\n",
    "        positions = info['positions']\n",
    "        symbols = info['symbols']\n",
    "\n",
    "        changed_positions = decompose_tuples(positions)\n",
    "        indexes = []\n",
    "        for i in range(len(changed_positions['old'])):\n",
    "            idx = positions.index(changed_positions['old'][i])\n",
    "            indexes.append(idx)\n",
    "            positions.extend(changed_positions['new'])\n",
    "            symbols.extend([symbols[idx]] * len(changed_positions['new'][i]))\n",
    "        positions = [pos for idx, pos in enumerate(positions) if idx not in indexes]\n",
    "        symbols = [sym for idx, sym in enumerate(symbols) if idx not in indexes]\n",
    "        \n",
    "        return {\n",
    "            'underlying_symbol': undl_symbol,\n",
    "            'positions': positions,\n",
    "            'symbols': symbols\n",
    "        }\n",
    "        \n",
    "    def create_pairs(df):\n",
    "        def get_axises(df):\n",
    "            def split(data):\n",
    "                \n",
    "                da = data.dropna().copy()\n",
    "                if da.empty:\n",
    "                    return []\n",
    "                \n",
    "                starts = da.index[np.where(da.index.diff()!=1)[0].tolist()].tolist()\n",
    "                ends =  da.index[np.where(da.index.diff(-1)!=-1)[0].tolist()].tolist()\n",
    "                \n",
    "                return list(zip(starts, ends))\n",
    "\n",
    "            axises = []\n",
    "            for i in range(2, len(df.columns)):\n",
    "                data = df.iloc[:, i]\n",
    "                seq = split(data)\n",
    "                \n",
    "                _ax = []\n",
    "                for s in seq:\n",
    "                    _ax.append(Axis(data.name, s[0], s[1]))\n",
    "                _ax = sorted(_ax, reverse=True)\n",
    "                if len(_ax) > 1:\n",
    "                    _ax = Axis.merge(_ax)\n",
    "                \n",
    "                [axises.append(a) for a in _ax]\n",
    "                \n",
    "            return deque(sorted(axises, reverse=True))\n",
    "            \n",
    "        pairs = []    \n",
    "        axises_deque = get_axises(df)\n",
    "        while len(axises_deque) >= 2:\n",
    "            base = axises_deque.popleft()\n",
    "            other = axises_deque.popleft()\n",
    "            new_axis = base - other\n",
    "            if len(axises_deque) > 0:\n",
    "                axises_deque.append(new_axis)\n",
    "                axises_deque = deque(sorted(list(axises_deque), reverse=True))\n",
    "            base_start = base.start if len(axises_deque) < 2 else other.start\n",
    "            pairs.append(((base_start, base.end, base.name), (other.start, other.end, other.name)))    \n",
    "        return pairs\n",
    "\n",
    "    def create_group(df):\n",
    "        info = get_new_seqments_info(df)\n",
    "        undl_symbol = info['underlying_symbol']\n",
    "        # positions = info['positions']\n",
    "        # symbols = info['symbols']\n",
    "        # positions = [(b[0], b[1], a) for a, b in zip(symbols, positions)]\n",
    "        pairs = create_pairs(df)\n",
    "        \n",
    "        df[undl_symbol].ffill(inplace=True)\n",
    "        work_dfs = []\n",
    "        pairs.sort(key=lambda x: x[0][0])\n",
    "        for pair in pairs:\n",
    "            start_pos = min(pair[0][0], pair[1][0])\n",
    "            end_pos = max(pair[0][1], pair[1][1])\n",
    "            data = df.loc[start_pos:end_pos, ['datetime', undl_symbol, pair[0][2], pair[1][2]]]\n",
    "            # ic(pair)\n",
    "            data['TotalPrice'] = data[pair[0][2]] + data[pair[1][2]]\n",
    "            data.bfill(inplace=True)\n",
    "            data.set_index('datetime', drop=True, inplace=True)\n",
    "            \n",
    "            data['Rise'] = data['TotalPrice'].shift(1) - data['TotalPrice']\n",
    "            \n",
    "            work_dfs.append(data)\n",
    "        \n",
    "        return work_dfs\n",
    "    \n",
    "    return create_group(df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_profit(all_groups):\n",
    "    all_profit = []\n",
    "    all_underlying = []\n",
    "    straddle_groups = []\n",
    "    for i, group in enumerate(tqdm(all_groups, desc='正在计算收益')):    \n",
    "        prices = group['prices']\n",
    "        prices = json.loads(prices)\n",
    "        df = pd.DataFrame.from_dict(prices, orient='index')\n",
    "        df = df.reset_index().rename(columns={'index': 'datetime'})\n",
    "        group = to_straddle_group(df)\n",
    "        rise = [g.loc[~pd.isnull(g['Rise']), 'Rise'] for g in group.copy()]\n",
    "        all_profit.append(pd.concat(rise).cumsum())\n",
    "        all_underlying.append(df.iloc[:, :2])\n",
    "        straddle_groups.append(group)\n",
    "\n",
    "        \n",
    "    total_profits = pd.concat(all_profit, axis=1)\n",
    "    total_profits.ffill(inplace=True)    \n",
    "    total_profits.fillna(0, inplace=True)\n",
    "    total = total_profits.sum(axis=1)\n",
    "    total.index = pd.to_datetime(total.index)\n",
    "    \n",
    "    underlying = pd.concat(all_underlying).drop_duplicates(subset=['datetime'])\n",
    "    underlying.sort_values('datetime', inplace=True)\n",
    "    underlying['datetime'] = pd.to_datetime(underlying['datetime'])\n",
    "    underlying.set_index('datetime', drop=True, inplace=True)\n",
    "    \n",
    "    \n",
    "    return underlying, total, total_profits, straddle_groups\n",
    "\n",
    "def get_chart_data(underlying, total_profits, timeframe='D'):\n",
    "    df1 = underlying.resample(timeframe).agg({\n",
    "                'open': 'first',\n",
    "                'high': 'max',\n",
    "                'low': 'min',\n",
    "                'close': 'last'\n",
    "            })\n",
    "    df1.dropna(how='all', inplace=True)\n",
    "    \n",
    "    df2 = total_profits.resample(timeframe).agg({\n",
    "                'open': 'first',\n",
    "                'high': 'max',\n",
    "                'low': 'min',\n",
    "                'close': 'last'\n",
    "            })\n",
    "    df2.dropna(how='all', inplace=True)\n",
    "    \n",
    "    return df1, df2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "正在计算收益: 12it [00:00, 28.97it/s]\n"
     ]
    }
   ],
   "source": [
    "all_groups = coll.find({'strategy_id': strategy_id})\n",
    "underlying, total, total_profits, straddle_groups = compute_profit(all_groups)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime\n",
       "2020-06-17 09:36:00    0.0000\n",
       "2020-06-17 09:37:00    0.0000\n",
       "2020-06-17 09:38:00    0.0000\n",
       "2020-06-17 09:39:00    0.0000\n",
       "2020-06-17 09:40:00    0.0000\n",
       "                        ...  \n",
       "2020-07-06 14:46:00   -1.6242\n",
       "2020-07-06 14:47:00   -1.6325\n",
       "2020-07-06 14:48:00   -1.6477\n",
       "2020-07-06 14:49:00   -1.6762\n",
       "2020-07-06 14:50:00   -1.6724\n",
       "Length: 2888, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def historical_volatility(prices, window=252):\n",
    "    returns = prices.pct_change().dropna()  # 计算收益率\n",
    "    volatility = returns.rolling(window=window, min_periods=1).std() * np.sqrt(window)  # 使用滚动窗口计算波动率，并年化\n",
    "    return volatility\n",
    "\n",
    "hvi = historical_volatility(underlying)\n",
    "hvi.rename(columns={'510050.SH':'open'},inplace=True)\n",
    "hvi['high'] = hvi['open']\n",
    "hvi['low'] = hvi['open']\n",
    "hvi['close'] = hvi['open']\n",
    "hvi = hvi.resample('1w').agg({\n",
    "            'open': 'first',\n",
    "            'high': 'max',\n",
    "            'low': 'min',\n",
    "            'close': 'last'\n",
    "        })\n",
    "hvi.dropna(how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hvi['open'].plot(figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hvi = historical_volatility(underlying)\n",
    "# hvi.loc[hvi['510050.SH'] >= 0.03]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "straddle_groups[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for group in coll.find({'strategy_id': strategy_id}):\n",
    "    prices = group['prices']\n",
    "    prices = json.loads(prices)\n",
    "    df = pd.DataFrame.from_dict(prices, orient='index')\n",
    "    df = df.reset_index().rename(columns={'index': 'datetime'})\n",
    "    \n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for df in dfs:\n",
    "    for i in range(2, len(df.columns)):\n",
    "        data = df.iloc[:, i]\n",
    "        data = data[data.notna()]\n",
    "        result.append([data.name, data.iloc[0], data.iloc[-1]])\n",
    "sorted(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_groups = coll.find({'strategy_id': strategy_id})\n",
    "straddle_groups = []\n",
    "for i, group in enumerate(tqdm(all_groups, desc='正在计算收益')):    \n",
    "    prices = group['prices']\n",
    "    prices = json.loads(prices)\n",
    "    df = pd.DataFrame.from_dict(prices, orient='index')\n",
    "    df = df.reset_index().rename(columns={'index': 'datetime'})\n",
    "    \n",
    "    # group = to_straddle_group(df)\n",
    "    # rise = [g.loc[~pd.isnull(g['Rise']), 'Rise'] for g in group.copy()]\n",
    "    # straddle_groups.append(group)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Axis:\n",
    "    \n",
    "    def __init__(self, name, start, end):\n",
    "        self.name = name\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Axis(name='{self.name}', start={self.start}, end={self.end})\"\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        \"\"\"根据开始位置进行比较，以实现排序。\"\"\"\n",
    "        if self.end < other.end:\n",
    "            return True\n",
    "        elif self.end == other.end:\n",
    "            return self.start > other.start\n",
    "        return False\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        if self.start <= other.start and self.end >= other.end:\n",
    "            return Axis(self.name, self.start, other.start) if other.start > self.start else None\n",
    "        \n",
    "        raise ValueError('不能消除数轴，请检查价格分组数据')\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    def merge(axes, gap=10):\n",
    "        if len(axes) < 2:\n",
    "            return axes\n",
    "        _axes = deque(sorted(axes).copy())\n",
    "        base = _axes.popleft()\n",
    "        new_axes = []\n",
    "        while len(_axes) > 0:\n",
    "            other = _axes.popleft()\n",
    "            if other.start - base.end <= gap:\n",
    "                base = Axis(base.name, base.start, other.end)\n",
    "            else:\n",
    "                new_axes.append(base)\n",
    "                base = other\n",
    "        new_axes.append(base)\n",
    "        \n",
    "        return new_axes\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pairs(df):\n",
    "    def get_axises(df):\n",
    "        def split(data):\n",
    "            \n",
    "            da = data.dropna().copy()\n",
    "            if da.empty:\n",
    "                return []\n",
    "            \n",
    "            starts = da.index[np.where(da.index.diff()!=1)[0].tolist()].tolist()\n",
    "            ends =  da.index[np.where(da.index.diff(-1)!=-1)[0].tolist()].tolist()\n",
    "            \n",
    "            return list(zip(starts, ends))\n",
    "\n",
    "        axises = []\n",
    "        for i in range(2, len(df.columns)):\n",
    "            data = df.iloc[:, i]\n",
    "            seq = split(data)\n",
    "            \n",
    "            _ax = []\n",
    "            for s in seq:\n",
    "                _ax.append(Axis(data.name, s[0], s[1]))\n",
    "            _ax = sorted(_ax, reverse=True)\n",
    "            if len(_ax) > 1:\n",
    "                _ax = Axis.merge(_ax)\n",
    "            \n",
    "            [axises.append(a) for a in _ax]\n",
    "            \n",
    "        return deque(sorted(axises, reverse=True))\n",
    "        \n",
    "    pairs = []    \n",
    "    axises_deque = get_axises(df)\n",
    "    while len(axises_deque) >= 2:\n",
    "        base = axises_deque.popleft()\n",
    "        other = axises_deque.popleft()\n",
    "        new_axis = base - other\n",
    "        if len(axises_deque) > 0:\n",
    "            axises_deque.append(new_axis)\n",
    "            axises_deque = deque(sorted(list(axises_deque), reverse=True))\n",
    "        base_start = base.start if len(axises_deque) < 2 else other.start\n",
    "        pairs.append(((base_start, base.end, base.name), (other.start, other.end, other.name)))    \n",
    "    return pairs\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for groups in straddle_groups:\n",
    "    for g in groups:\n",
    "        print(g.iloc[[0, -1], 1:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制整体收益\n",
    "total.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "undl_name = underlying.columns[0]\n",
    "undl_data = underlying[undl_name]\n",
    "undl_bars, profits = get_chart_data(undl_data, total, timeframe='60min')\n",
    "\n",
    "chart_1 = JupyterChart()\n",
    "chart_1.set(profits)\n",
    "chart_1.load()\n",
    "\n",
    "chart_2 = JupyterChart()\n",
    "chart_2.set(undl_bars)\n",
    "chart_2.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whole_price = get_whole_price(straddle_groups[i])\n",
    "# p = whole_price['adjust_price'] \n",
    "\n",
    "for j in range(len(straddle_groups[i])):\n",
    "    p = straddle_groups[i][j]['TotalPrice']\n",
    "    i += 1\n",
    "\n",
    "    N = 60\n",
    "    upper_band = p.rolling(window=N).max()\n",
    "    lower_band = p.rolling(window=N).min()\n",
    "    middle_band = (upper_band + lower_band) / 2\n",
    "\n",
    "    plt.figure(figsize=(20, 6))\n",
    "    p.plot(figsize=(20, 6))\n",
    "    upper_band.plot()\n",
    "    lower_band.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_price = get_whole_price(straddle_groups[i])\n",
    "p = whole_price['adjust_price'] \n",
    "i += 1\n",
    "N = 60\n",
    "upper_band = p.rolling(window=N).max()\n",
    "lower_band = p.rolling(window=N).min()\n",
    "middle_band = (upper_band + lower_band) / 2\n",
    "plt.figure(figsize=(20, 6))\n",
    "p.plot(figsize=(20, 6))\n",
    "upper_band.plot()\n",
    "lower_band.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_whole_price(straddle_group):\n",
    "    last_price = 0\n",
    "    group = []\n",
    "    for j in range(len(straddle_group)):\n",
    "        straddle_group[j]['adjust_price'] = straddle_group[j]['TotalPrice'] + last_price\n",
    "        last_price = 0 #straddle_group[j]['TotalPrice'].iloc[-1]\n",
    "        tmp = straddle_group[j].copy()\n",
    "        old_columns = list(tmp.columns)[1:3]\n",
    "        new_columns = ['symbol_1', 'symbol_2']\n",
    "        tmp.rename(columns=dict(zip(old_columns, new_columns)), inplace=True)\n",
    "        group.append(tmp)\n",
    "        \n",
    "    return pd.concat(group)\n",
    "\n",
    "get_whole_price(straddle_groups[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_profit(total_profits, n):\n",
    "    def remove_head_tail_continuous_n(series):\n",
    "        data = total_profits.iloc[:, n].copy()\n",
    "        diff = data.loc[data!=data.shift()]\n",
    "        start = data.index[0]\n",
    "        end = data.index[-1]\n",
    "        if len(diff) > 0:\n",
    "            start = diff.index[1]\n",
    "            end = diff.index[-1]\n",
    "        return series[start: end]\n",
    "\n",
    "    return remove_head_tail_continuous_n(total_profits.iloc[:, n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 到出到通达信格式\n",
    "def to_tdx(total_profits):\n",
    "    for i in trange(len(total_profits.columns)):\n",
    "        profit = get_profit(total_profits, i)\n",
    "        data = pd.DataFrame(profit)\n",
    "        data['Rise'] = (data['Rise'].round(4) + 1) \n",
    "        data.rename(columns={'Rise': 'Open'}, inplace=True)\n",
    "        data.reset_index(inplace=True)\n",
    "        data['date'] = pd.date_range(start=data.iloc[0]['datetime'][:10], periods=len(data))\n",
    "        data['High'] = data['Open']\n",
    "        data['Low'] = data['Open']\n",
    "        data['Close'] = data['Open']\n",
    "        data['volume'] = 1\n",
    "        data['amount'] = 1\n",
    "        data = data[['date', 'Open', 'High', 'Low', 'Close', 'volume', 'amount']]\n",
    "        data.to_csv(f'd:\\\\temp\\\\oquant\\\\{i}.txt', sep=',', header=False, index=False)\n",
    "\n",
    "to_tdx(total_profits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.models import ColumnDataSource, HoverTool\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "# 定义计算MACD指标的函数\n",
    "def calculate_macd(data, short_window=12, long_window=26, signal_window=9):\n",
    "    data['ShortEMA'] = data['Close'].ewm(span=short_window, adjust=False).mean()\n",
    "    data['LongEMA'] = data['Close'].ewm(span=long_window, adjust=False).mean()\n",
    "    data['MACD'] = data['ShortEMA'] - data['LongEMA']\n",
    "    data['Signal Line'] = data['MACD'].ewm(span=signal_window, adjust=False).mean()\n",
    "    data['Histogram'] = data['MACD'] - data['Signal Line']\n",
    "    return data\n",
    "\n",
    "profit = get_profit(total_profits, 100)\n",
    "data = pd.DataFrame(profit)\n",
    "data['Rise'] = 1 + data['Rise']\n",
    "data.rename(columns={'Rise': 'Open'}, inplace=True)\n",
    "data['High'] = data['Open']\n",
    "data['Low'] = data['Open']\n",
    "data['Close'] = data['Open']\n",
    "data.reset_index(inplace=True)\n",
    "data.rename(columns={'datetime': 'Date'}, inplace=True)\n",
    "# data.index = pd.to_datetime(data.index)\n",
    "\n",
    "df = calculate_macd(data)\n",
    "\n",
    "# 创建数据源\n",
    "source = ColumnDataSource(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建绘图对象\n",
    "p = figure(x_axis_type='datetime', title='MACD Indicator', height=300, width=800, y_range=(min(df['MACD'])*1.1, max(df['MACD']) * 1.1))\n",
    "\n",
    "# 绘制MACD线\n",
    "p.line(x='Date', y='MACD', source=source, legend_label='MACD', color='blue')\n",
    "\n",
    "# 绘制MACD信号线\n",
    "p.line(x='Date', y='Signal Line', source=source, legend_label='Signal Line', color='red')\n",
    "\n",
    "# 绘制MACD柱状图\n",
    "p.vbar(x='Date', top='Histogram', width=0.9, source=source, legend_label='Histogram', \n",
    "       fill_color='green', line_color='black')\n",
    "\n",
    "# 添加悬停工具\n",
    "hover = HoverTool()\n",
    "hover.tooltips = [(\"Date\", \"@Date{%F}\"), (\"MACD\", \"@MACD\"), (\"Signal Line\", \"@{Signal Line}\"), (\"Histogram\", \"@Histogram\")]\n",
    "hover.formatters = {'@Date': 'datetime'}\n",
    "p.add_tools(hover)\n",
    "\n",
    "# 设置图例位置\n",
    "p.legend.location = 'top_left'\n",
    "\n",
    "# 在Jupyter Notebook中显示图表\n",
    "output_notebook()\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.models import ColumnDataSource, HoverTool\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "# 定义计算MACD指标的函数\n",
    "def calculate_macd(data, short_window=12, long_window=26, signal_window=9):\n",
    "    data['ShortEMA'] = data['Close'].ewm(span=short_window, adjust=False).mean()\n",
    "    data['LongEMA'] = data['Close'].ewm(span=long_window, adjust=False).mean()\n",
    "    data['MACD'] = data['ShortEMA'] - data['LongEMA']\n",
    "    data['Signal Line'] = data['MACD'].ewm(span=signal_window, adjust=False).mean()\n",
    "    data['Histogram'] = data['MACD'] - data['Signal Line']\n",
    "    return data\n",
    "\n",
    "# 示例数据，假设已经有股票价格数据\n",
    "data = {\n",
    "    'Date': pd.date_range(start='2022-01-01', periods=100),\n",
    "    'Close': [100 + 2 * i for i in range(100)]  # 假设股票价格\n",
    "}\n",
    "\n",
    "# 转换为DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 计算MACD指标\n",
    "df = calculate_macd(df)\n",
    "\n",
    "# 创建数据源\n",
    "source = ColumnDataSource(df)\n",
    "\n",
    "# 创建绘图对象\n",
    "p = figure(x_axis_type='datetime', title='MACD Indicator', height=300, width=800)\n",
    "\n",
    "# 绘制MACD线\n",
    "p.line(x='Date', y='MACD', source=source, legend_label='MACD', color='blue')\n",
    "\n",
    "# 绘制MACD信号线\n",
    "p.line(x='Date', y='Signal Line', source=source, legend_label='Signal Line', color='red')\n",
    "\n",
    "# 绘制MACD柱状图\n",
    "p.vbar(x='Date', top='Histogram', width=0.9, source=source, legend_label='Histogram', \n",
    "       fill_color='green', line_color='black')\n",
    "\n",
    "# 添加悬停工具\n",
    "hover = HoverTool()\n",
    "hover.tooltips = [(\"Date\", \"@Date{%F}\"), (\"MACD\", \"@MACD\"), (\"Signal Line\", \"@{Signal Line}\"), (\"Histogram\", \"@Histogram\")]\n",
    "hover.formatters = {'@Date': 'datetime'}\n",
    "p.add_tools(hover)\n",
    "\n",
    "# 设置图例位置\n",
    "p.legend.location = 'top_left'\n",
    "\n",
    "# 在Jupyter Notebook中显示图表\n",
    "output_notebook()\n",
    "show(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意： 轻易不要运行，太耗时了！！！\n",
    "# 绘制每个交易单元的收益\n",
    "for i in range(len(total_profits.columns)):\n",
    "    profit = total_profits.iloc[:i]\n",
    "    profit.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oquant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
